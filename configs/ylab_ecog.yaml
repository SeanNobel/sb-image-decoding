# ==== Dataset ==== #
dataset: Brain2FaceYLabECoGDataset
face_data_root: /work/data/ECoG/E0030/
ecog_data_root: /storage/data/ECoG/E0030/Raw/Mat2k/
sync_data_path: /work/data/ECoG/rishido/E0030sync_trigger.csv

# ==== Preprocess ==== #
# Common
preproc_name: first_test
seq_len: 3 # segment length in seconds
subject_multiprocess: False
start_subj: 0
end_subj: 8
debug: False

fps: 30

# Brain
# brain_resample_rate: 120 # Hz
# brain_filter_low: 1.0 # Hz
# brain_filter_high: 60 # Hz
clamp_lim: 20 # values after robust scaling
baseline_len: 0.5 # sec
# shift_brain: False
# shift_len: 150 # ms


# ==== Training ==== #
train_name: first_test

split: deep # shallow / deep / subject_random / subject_each
# subject_random: picks 20% sessions for test, without considering subjects' identity
# subject_each: each subject has one or two test sessions (currently not working)

train_ratio: 0.8
chance: False
# ðŸ”¥ FIXME: with too large a batchsize there isn't enough 
# ðŸ”¥ FIXME: samples in the eval set, and the CLIPLoss produces nans silently
batch_size: 64
lr: 0.005
lr_scheduler: cosine # cosine or multistep
lr_multistep_mlstns: [0.4, 0.6, 0.8, 0.9]
lr_step_gamma: 0.5
epochs: 500
reduction: mean
init_temperature: 5.0

cuda_id: 0

use_wandb: False


# ==== Architecture ==== #
# Common
F: 709

# Brain
D1: 270
D2: 320
K: 32
d_drop: 0.3 # Channel distance for spatial dropout
# NOTE: setting these 2 is the key that BrainEncoder downsamples EEG from 120Hz to 30Hz
final_kernel_size: 2
final_stride: 2

seed: 1234