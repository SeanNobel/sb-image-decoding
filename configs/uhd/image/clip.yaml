# ==== Preprocessing ==== #
preproc_name: init

data_root: /mnt/tsukuyomi/uhd-eeg/
# ica_data_root: /home/sensho/brain2face/driving_ica/

segment_in_preproc: True

start_subj: 0
end_subj: 22

seq_len: 3 # segment length in seconds

# ---- Face ---- #
fps: 30

face_extractor:
  mode: mesh
  output_size: 256
  eyes_dist_mult: 4
  movement_alert_thresh: 50 # px

# ---- Brain ---- #
num_channels: 128
brain_filter_low: 1.0 # Hz
brain_filter_high: 60 # Hz
brain_orig_sfreq: 250 # Hz
brain_resample_sfreq: 120 # Hz
clamp_lim: 20 # values after robust scaling
baseline_ratio: 0.2 # ratio compared to segment length
# shift_brain: False
# shift_len: 150 # ms

eeg_load_bufsize: 1000 # samples


# ==== Training ==== #
project_name: neuro-diffusion_uhd_clip
train_name: image # Will be updated when it's a sweep
debug: False

dataset: UHD # UHD / YLabECoG / StyleGAN

montage_path: brain2face/utils/montages/electrodes_uhd.xml
layout: ch_locations_2d

F: 512 # CLIP embedding dimension

reduce_time: True # Reduce video to image

vision:
  type: static # static (image) or dynamic (video)
  reduction: extract # extract or mean. Only for reduce_time: True
  pretrained: False # Whether to embed images using pretrained CLIP model
  model: ViT
  pretrained_model: ViT-B/32 # Used if pretrained is False
  encoded: False # False is basically only for StyleGAN
  
vision_encoder:
  image_size: 256
  patch_size: 32
  dim: ${F}
  depth: 6
  heads: 16
  mlp_dim: 2048
  dropout: 0.1
  emb_dropout: 0.1

# Brain encoder
D1: 270
D2: 320
K: 32
d_drop: 0.1 # Channel distance for spatial dropout
# NOTE: setting these 2 is the key that BrainEncoder downsamples EEG from 120Hz to 30Hz
final_ksize: 2
final_stride: 2
head_activation: False

split: shallow # shallow / deep / subject_random / subject_each
train_ratio: 0.8
batch_size: 64
lr: 0.005
lr_scheduler: multistep # cosine or multistep
lr_multistep_mlstns: [0.4, 0.6, 0.8, 0.9]
lr_step_gamma: 0.5
epochs: 500
reduction: mean
init_temperature: 5.0

accum_grad: False

chance: False

test_with_whole: True

num_workers: 4

seed: 1234

cuda_id: 2

sweep_count: 20
sweep_config:
  method: bayes
  metric:
    name: test_top10_acc
    goal: maximize
  parameters:
    split:
      values: [deep, shallow]
    d_drop:
      values: [0.1, 0.3, 0.5]
    vision.encoded:
      values: [True, False]
    head_activation:
      values: [True, False]
    final_ksize_stride:
      values: [1, 2]
    vision.reduction:
      values: [extract, mean]

# ==== Evaluation ==== #
eval:
  split: shallow
  d_drop: 0.1
  vision:
    reduction: extract
    encoded: False
  head_activation: False
  final_ksize_stride: 2

as_h5: False
for_webdataset: False